Removing conda
Loading conda
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Loading checkpoint shards:   0%|          | 0/38 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/38 [00:00<00:35,  1.05it/s]Loading checkpoint shards:   5%|▌         | 2/38 [00:01<00:31,  1.15it/s]Loading checkpoint shards:   8%|▊         | 3/38 [00:02<00:29,  1.18it/s]Loading checkpoint shards:  11%|█         | 4/38 [00:03<00:28,  1.18it/s]Loading checkpoint shards:  13%|█▎        | 5/38 [00:04<00:27,  1.19it/s]Loading checkpoint shards:  16%|█▌        | 6/38 [00:05<00:26,  1.20it/s]Loading checkpoint shards:  18%|█▊        | 7/38 [00:05<00:26,  1.18it/s]Loading checkpoint shards:  21%|██        | 8/38 [00:06<00:26,  1.14it/s]Loading checkpoint shards:  24%|██▎       | 9/38 [00:07<00:25,  1.13it/s]Loading checkpoint shards:  26%|██▋       | 10/38 [00:08<00:24,  1.16it/s]Loading checkpoint shards:  29%|██▉       | 11/38 [00:09<00:23,  1.17it/s]Loading checkpoint shards:  32%|███▏      | 12/38 [00:10<00:22,  1.18it/s]Loading checkpoint shards:  34%|███▍      | 13/38 [00:11<00:21,  1.16it/s]Loading checkpoint shards:  37%|███▋      | 14/38 [00:12<00:20,  1.17it/s]Loading checkpoint shards:  39%|███▉      | 15/38 [00:12<00:19,  1.17it/s]Loading checkpoint shards:  42%|████▏     | 16/38 [00:13<00:18,  1.16it/s]Loading checkpoint shards:  45%|████▍     | 17/38 [00:14<00:18,  1.16it/s]Loading checkpoint shards:  47%|████▋     | 18/38 [00:15<00:17,  1.17it/s]Loading checkpoint shards:  50%|█████     | 19/38 [00:16<00:16,  1.17it/s]Loading checkpoint shards:  53%|█████▎    | 20/38 [00:17<00:15,  1.16it/s]Loading checkpoint shards:  55%|█████▌    | 21/38 [00:18<00:14,  1.15it/s]Loading checkpoint shards:  58%|█████▊    | 22/38 [00:18<00:13,  1.15it/s]Loading checkpoint shards:  61%|██████    | 23/38 [00:19<00:13,  1.13it/s]Loading checkpoint shards:  63%|██████▎   | 24/38 [00:20<00:12,  1.12it/s]Loading checkpoint shards:  66%|██████▌   | 25/38 [00:21<00:11,  1.13it/s]Loading checkpoint shards:  68%|██████▊   | 26/38 [00:22<00:10,  1.15it/s]Loading checkpoint shards:  71%|███████   | 27/38 [00:23<00:09,  1.16it/s]Loading checkpoint shards:  74%|███████▎  | 28/38 [00:24<00:08,  1.17it/s]Loading checkpoint shards:  76%|███████▋  | 29/38 [00:24<00:07,  1.17it/s]Loading checkpoint shards:  79%|███████▉  | 30/38 [00:25<00:06,  1.18it/s]Loading checkpoint shards:  82%|████████▏ | 31/38 [00:26<00:05,  1.19it/s]Loading checkpoint shards:  84%|████████▍ | 32/38 [00:27<00:05,  1.19it/s]Loading checkpoint shards:  87%|████████▋ | 33/38 [00:28<00:04,  1.18it/s]Loading checkpoint shards:  89%|████████▉ | 34/38 [00:29<00:03,  1.20it/s]Loading checkpoint shards:  92%|█████████▏| 35/38 [00:29<00:02,  1.20it/s]Loading checkpoint shards:  95%|█████████▍| 36/38 [00:30<00:01,  1.20it/s]Loading checkpoint shards:  97%|█████████▋| 37/38 [00:31<00:00,  1.34it/s]Loading checkpoint shards: 100%|██████████| 38/38 [00:31<00:00,  1.46it/s]Loading checkpoint shards: 100%|██████████| 38/38 [00:31<00:00,  1.19it/s]
  0%|          | 0/209 [00:00<?, ?it/s]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  0%|          | 1/209 [00:34<1:59:32, 34.48s/it]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  1%|          | 2/209 [01:04<1:50:28, 32.02s/it]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  1%|▏         | 3/209 [01:16<1:18:31, 22.87s/it]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  2%|▏         | 4/209 [02:30<2:26:17, 42.82s/it]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  2%|▏         | 5/209 [03:41<3:00:50, 53.19s/it]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  3%|▎         | 6/209 [04:32<2:57:29, 52.46s/it]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  3%|▎         | 7/209 [05:08<2:37:55, 46.91s/it]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  4%|▍         | 8/209 [06:37<3:21:59, 60.30s/it]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
slurmstepd-gpu016: error: *** JOB 25899190 ON gpu016 CANCELLED AT 2024-11-03T15:54:33 ***
