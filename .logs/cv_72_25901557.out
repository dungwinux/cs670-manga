Removing conda
Loading conda
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
qwen_72
Loading checkpoint shards:   0%|          | 0/38 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/38 [00:39<24:03, 39.00s/it]Loading checkpoint shards:   5%|▌         | 2/38 [01:29<27:26, 45.72s/it]Loading checkpoint shards:   8%|▊         | 3/38 [02:17<27:13, 46.67s/it]Loading checkpoint shards:  11%|█         | 4/38 [02:52<23:51, 42.09s/it]Loading checkpoint shards:  13%|█▎        | 5/38 [03:30<22:25, 40.77s/it]Loading checkpoint shards:  16%|█▌        | 6/38 [04:04<20:28, 38.40s/it]Loading checkpoint shards:  18%|█▊        | 7/38 [04:44<20:01, 38.76s/it]Loading checkpoint shards:  21%|██        | 8/38 [05:25<19:45, 39.53s/it]Loading checkpoint shards:  24%|██▎       | 9/38 [06:08<19:38, 40.65s/it]Loading checkpoint shards:  26%|██▋       | 10/38 [06:42<18:00, 38.60s/it]Loading checkpoint shards:  29%|██▉       | 11/38 [07:13<16:24, 36.45s/it]Loading checkpoint shards:  32%|███▏      | 12/38 [08:16<19:15, 44.46s/it]Loading checkpoint shards:  34%|███▍      | 13/38 [08:49<17:00, 40.84s/it]Loading checkpoint shards:  37%|███▋      | 14/38 [09:35<16:59, 42.47s/it]Loading checkpoint shards:  39%|███▉      | 15/38 [10:17<16:14, 42.36s/it]Loading checkpoint shards:  42%|████▏     | 16/38 [10:53<14:47, 40.36s/it]Loading checkpoint shards:  45%|████▍     | 17/38 [11:25<13:16, 37.94s/it]Loading checkpoint shards:  47%|████▋     | 18/38 [11:58<12:07, 36.36s/it]Loading checkpoint shards:  50%|█████     | 19/38 [13:26<16:26, 51.91s/it]Loading checkpoint shards:  53%|█████▎    | 20/38 [14:04<14:19, 47.77s/it]Loading checkpoint shards:  55%|█████▌    | 21/38 [14:46<13:04, 46.16s/it]Loading checkpoint shards:  58%|█████▊    | 22/38 [15:22<11:27, 42.97s/it]Loading checkpoint shards:  61%|██████    | 23/38 [16:14<11:26, 45.76s/it]Loading checkpoint shards:  63%|██████▎   | 24/38 [17:38<13:20, 57.20s/it]Loading checkpoint shards:  66%|██████▌   | 25/38 [18:21<11:29, 53.03s/it]Loading checkpoint shards:  68%|██████▊   | 26/38 [19:03<09:56, 49.73s/it]Loading checkpoint shards:  71%|███████   | 27/38 [19:41<08:25, 45.94s/it]Loading checkpoint shards:  74%|███████▎  | 28/38 [20:32<07:55, 47.53s/it]Loading checkpoint shards:  76%|███████▋  | 29/38 [21:07<06:33, 43.75s/it]Loading checkpoint shards:  79%|███████▉  | 30/38 [21:38<05:21, 40.13s/it]Loading checkpoint shards:  82%|████████▏ | 31/38 [22:11<04:25, 37.99s/it]Loading checkpoint shards:  84%|████████▍ | 32/38 [22:51<03:51, 38.54s/it]Loading checkpoint shards:  87%|████████▋ | 33/38 [23:25<03:06, 37.25s/it]Loading checkpoint shards:  89%|████████▉ | 34/38 [23:56<02:20, 35.14s/it]Loading checkpoint shards:  92%|█████████▏| 35/38 [24:38<01:51, 37.28s/it]Loading checkpoint shards:  95%|█████████▍| 36/38 [25:18<01:16, 38.25s/it]Loading checkpoint shards:  97%|█████████▋| 37/38 [25:35<00:31, 31.72s/it]Loading checkpoint shards: 100%|██████████| 38/38 [25:56<00:00, 28.57s/it]Loading checkpoint shards: 100%|██████████| 38/38 [25:56<00:00, 40.96s/it]
  0%|          | 0/209 [00:00<?, ?it/s]/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:603: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/scratch/workspace/ctpham_umass_edu-llama/envs/manga/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:620: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  0%|          | 0/209 [00:23<?, ?it/s]
Traceback (most recent call last):
  File "/work/pi_miyyer_umass_edu/ctpham/cs670-manga/translation/qwen.py", line 168, in <module>
    inference(model, processor, df, output_file)
  File "/work/pi_miyyer_umass_edu/ctpham/cs670-manga/translation/qwen.py", line 122, in inference
    df_specific['text_translated'] = [
  File "/work/pi_miyyer_umass_edu/ctpham/cs670-manga/translation/qwen.py", line 123, in <listcomp>
    extract_tag_text(extract_tag_text(output_text, f'item_{j}').strip(), 'translation').strip() or "" 
AttributeError: 'NoneType' object has no attribute 'strip'
